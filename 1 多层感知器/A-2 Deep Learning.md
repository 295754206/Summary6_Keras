#### 深度学习 

* 深度学习 ⊂ 机器学习 ⊂ 人工智能
* 深度学习的定义：一种实现机器学习的技术

#### 深度学习是一种神经网络

* 输入层
* 隐藏层（一个或多个，每一层的神经元用来 特征抽取 和 转换）
* 输出层

#### 深度学习的神经网络种类

* 多层感知器（Multilayer Perceptron，MLP）

  * 回归与分类问题

  * 如果隐藏层超过2层，这个多层感知器就是一种深度神经网络（DNN）
  * 输入层  -> （1个或多个）隐藏层  ->  输出层

* 卷积神经网络（Convolutional Neural Network，CNN）

  * 计算机视觉

  * 当数据进入卷积神经网络的输入层后，使用多组 卷积层（Convolution Layers）和 池化层（Pooling Layers）来自动萃取图像特征后，进入 全连接层，最后在输出层输出图像处理结果
  * 输入层  ->  卷积层->池化层->......->卷积层->池化层  ->  全连接层  ->  输出层

* 循环神经网络（Recurrent Neural Network，RNN）

  * 自然语言处理（处理声音、语言和影片等序列资料的神经网络）
  * 循环神经网络是一种拥有短期记忆力的神经网络
  * 隐藏层的前一次输出成为下一次的输入，让学习成果保留至下一次，如此神经网络就拥有记忆力（RNN只有短期记忆力）
  * 输入层  ->  隐藏层 **↻**  ->  输出层

#### 感知器 （Perceptron）

* 权重：重要度 或 信赖度 的意思
* 图例：

​                输入层：                                                输出层：

​                     **x1**          ----w1---->

​                     **x2**          ----w2---->

​                     **x3**          ----w3---->             **（ Σ xi*wi ）+ b  |  f()**             -----**t**---->

​                                .......                                         **感知器**

​                     **xn**         ----w4---->

​					       o---- b（bias）---->

* 即： t = f（z）= f（Σ xi*wi + b ）

*  **f()** 称之为：启动函数（Activation Function），用来判断是否激活神经元/感知器
  * 本例中启动函数使用的是阶梯函数（如果wx+b > s 为1否则为0）

#### 张量（Tensor）

* 张量的定义

  * 张量就是不同大小维度（Dimension），也称之为轴（Axis）的多维阵列，基本形状如下：
    * （样本数，特征1，特征2 ......）
  * 例如图片数据的形状：
    * （样本数，宽，高，色彩数）
  * 上述例子张量的维度为4，也称之为轴数，或等级（Rank）

* 0D张量

  * 纯数值（Scalar），或称为纯量值张量（Scalar Tensor），即float32或float64的数值数据

    ```python
    import numpy as np
    
    x = np.array(10.5)
    print(x)
    print(x.ndim)         # 输出tensor的维度
    ```

    ```python
    10.5
    0
    ```

* 1D张量

  * 向量，一个维度的一维数组（可分割为一个组）（一个轴）

    ```python
    x = np.array([1,2,3,4])
    print(x)
    print(x.ndim)
    ```

    ```python
    [1,2,3,4]
    1					  # 一个大向量
    ```

* 2D张量

  * 矩阵，2维矩阵，有2个轴

  * 1000名员工，每个员工3个数据：（1000，3）

  * 500篇文章，统计5000个字出现频率：（500，5000）

    ``` python
    x = np.array([
    	[1,2,3],
        [4,5,6],
        [7,8,9]
    ])
    print(x)
    print(x.ndim)
    print(x.shape)
    ```

    ```python
    [[1,2,3],
     [4,5,6],
     [7,8,9]]
    2					   # 第一层大向量，到最后一层共2层
    (3,3)
    ```

* 3D张量

  * 每一个元素是一个矩阵

  * 股票价格，前1000天的价格，每个交易日240分钟，每分钟有3个价格：（1000，240，3）

    ```python
    x = np.array([
        [
            [11,12,13]
            [21,22,23]
        ],[
            [31,32,33],
            [41,42,43]
        ],[
            [51,52,53],
            [61,62,63]
        ]
    ])
    print(x)
    print(x.ndim)
    print(x.shape)
    ```

    ```python
    [[[11,12,13]
      [21,22,23]]
        
     [[31,32,33]
      [41,42,43]]
        
     [[51,52,53]
      [61,62,63]]]
    3
    (3,2,3)				   # 从大到小分，以基础向量为底有3层（3D），每一层有3，2，3个子元素
    ```

* 4D张量

  * 100张照片组成的照片集（样本数100张，宽256px，高256px，RGB三原色）：（100，256，256，3）

* 5D张量
  * 视频（每秒240个画面，共10秒）：（10，240，256，256，3）

#### 二维向量的逐元素加减乘除和点乘运算

```python
import numpy as np

a = np.array([[1, 2], [3, 4]])
print("a=")
print(a)

b = np.array([[5, 6], [7, 8]])
print("b=")
print(b)

c1 = a + b
c2 = a - b
c3 = a * b
c4 = a / b

# 逐元素加减乘除
print("c1=")
print(c1)
print("c2=")
print(c2)
print("c3=")
print(c3)
print("c4=")
print(c4)

# 矩阵的点乘运算
d = a.dot(b)
print("a.dot(b)=")
print(d)
```

```python
a=
[[1 2]
 [3 4]]
b=
[[5 6]
 [7 8]]
c1=
[[ 6  8]
 [10 12]]
c2=
[[-4 -4]
 [-4 -4]]
c3=
[[ 5 12]
 [21 32]]
c4=
[[0.2        0.33333333]
 [0.42857143 0.5       ]]
a.dot(b)=
[[19 22]
 [43 50]]
```

